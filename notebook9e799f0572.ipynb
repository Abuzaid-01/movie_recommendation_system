{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:22.230938Z",
     "iopub.status.busy": "2025-09-25T13:58:22.230624Z",
     "iopub.status.idle": "2025-09-25T13:58:22.237149Z",
     "shell.execute_reply": "2025-09-25T13:58:22.236044Z",
     "shell.execute_reply.started": "2025-09-25T13:58:22.230909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import catboost as cb  # Comment out if not installed\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:24.682370Z",
     "iopub.status.busy": "2025-09-25T13:58:24.682004Z",
     "iopub.status.idle": "2025-09-25T13:58:25.636783Z",
     "shell.execute_reply": "2025-09-25T13:58:25.635811Z",
     "shell.execute_reply.started": "2025-09-25T13:58:24.682348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Train shape: (524164, 11)\n",
      "Test shape: (174722, 10)\n",
      "Columns: ['id', 'RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality', 'InstrumentalScore', 'LivePerformanceLikelihood', 'MoodScore', 'TrackDurationMs', 'Energy', 'BeatsPerMinute']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/playground-series-s5e9/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s5e9/test.csv\")\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Columns: {list(train.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:27.501870Z",
     "iopub.status.busy": "2025-09-25T13:58:27.501571Z",
     "iopub.status.idle": "2025-09-25T13:58:27.514721Z",
     "shell.execute_reply": "2025-09-25T13:58:27.513909Z",
     "shell.execute_reply.started": "2025-09-25T13:58:27.501849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    \"\"\"Create sophisticated features based on music domain knowledge\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Musical ratio features using actual column names\n",
    "    df_new['Energy_VocalContent_Ratio'] = df_new['Energy'] / (df_new['VocalContent'] + 1e-8)\n",
    "    df_new['Mood_Energy_Ratio'] = df_new['MoodScore'] / (df_new['Energy'] + 1e-8)\n",
    "    df_new['Loudness_Energy_Product'] = df_new['AudioLoudness'] * df_new['Energy']\n",
    "    df_new['Rhythm_Mood_Product'] = df_new['RhythmScore'] * df_new['MoodScore']\n",
    "    \n",
    "    # Tempo-related features\n",
    "    df_new['Duration_Minutes'] = df_new['TrackDurationMs'] / 60000\n",
    "    df_new['Rhythm_Duration_Ratio'] = df_new['RhythmScore'] / (df_new['Duration_Minutes'] + 1e-8)\n",
    "    df_new['Energy_Duration_Ratio'] = df_new['Energy'] / (df_new['Duration_Minutes'] + 1e-8)\n",
    "    \n",
    "    # Audio complexity features\n",
    "    df_new['Audio_Complexity'] = df_new['VocalContent'] * df_new['Energy'] * df_new['MoodScore']\n",
    "    df_new['Musical_Intensity'] = df_new['AudioLoudness'] * df_new['Energy'] * df_new['RhythmScore']\n",
    "    df_new['Performance_Quality'] = df_new['LivePerformanceLikelihood'] * df_new['AcousticQuality']\n",
    "    \n",
    "    # Acoustic vs Electronic indicator\n",
    "    df_new['Acoustic_vs_Electronic'] = df_new['AcousticQuality'] / (df_new['InstrumentalScore'] + 1e-8)\n",
    "    \n",
    "    # Binned categorical features\n",
    "    df_new['Energy_Bin'] = pd.cut(df_new['Energy'], bins=5, labels=[0,1,2,3,4])\n",
    "    df_new['Mood_Bin'] = pd.cut(df_new['MoodScore'], bins=5, labels=[0,1,2,3,4])\n",
    "    df_new['Vocal_Bin'] = pd.cut(df_new['VocalContent'], bins=5, labels=[0,1,2,3,4])\n",
    "    df_new['Rhythm_Bin'] = pd.cut(df_new['RhythmScore'], bins=5, labels=[0,1,2,3,4])\n",
    "    \n",
    "    # Polynomial features for key relationships\n",
    "    df_new['Energy_Squared'] = df_new['Energy'] ** 2\n",
    "    df_new['RhythmScore_Squared'] = df_new['RhythmScore'] ** 2\n",
    "    df_new['MoodScore_Squared'] = df_new['MoodScore'] ** 2\n",
    "    df_new['VocalContent_Squared'] = df_new['VocalContent'] ** 2\n",
    "    \n",
    "    # Log transformations for skewed features\n",
    "    df_new['TrackDurationMs_Log'] = np.log1p(df_new['TrackDurationMs'])\n",
    "    df_new['AudioLoudness_Log'] = np.log1p(df_new['AudioLoudness'] - df_new['AudioLoudness'].min() + 1)\n",
    "    \n",
    "    # Statistical features across audio characteristics\n",
    "    audio_cols = ['RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality', \n",
    "                  'InstrumentalScore', 'MoodScore', 'Energy']\n",
    "    df_new['Audio_Features_Mean'] = df_new[audio_cols].mean(axis=1)\n",
    "    df_new['Audio_Features_Std'] = df_new[audio_cols].std(axis=1)\n",
    "    df_new['Audio_Features_Median'] = df_new[audio_cols].median(axis=1)\n",
    "    df_new['Audio_Features_Range'] = df_new[audio_cols].max(axis=1) - df_new[audio_cols].min(axis=1)\n",
    "    df_new['Audio_Features_Skew'] = df_new[audio_cols].skew(axis=1)\n",
    "    \n",
    "    # Interaction features between related audio characteristics\n",
    "    df_new['Vocal_Acoustic_Interaction'] = df_new['VocalContent'] * df_new['AcousticQuality']\n",
    "    df_new['Rhythm_Energy_Interaction'] = df_new['RhythmScore'] * df_new['Energy']\n",
    "    df_new['Mood_Live_Interaction'] = df_new['MoodScore'] * df_new['LivePerformanceLikelihood']\n",
    "    \n",
    "    # Genre-style indicators (based on feature combinations)\n",
    "    df_new['Electronic_Indicator'] = (df_new['InstrumentalScore'] > 0.7) & (df_new['AcousticQuality'] < 0.3)\n",
    "    df_new['Acoustic_Indicator'] = (df_new['AcousticQuality'] > 0.7) & (df_new['InstrumentalScore'] < 0.3)\n",
    "    df_new['Vocal_Heavy_Indicator'] = df_new['VocalContent'] > 0.8\n",
    "    df_new['High_Energy_Indicator'] = df_new['Energy'] > 0.8\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:33.772800Z",
     "iopub.status.busy": "2025-09-25T13:58:33.772509Z",
     "iopub.status.idle": "2025-09-25T13:58:33.780193Z",
     "shell.execute_reply": "2025-09-25T13:58:33.779023Z",
     "shell.execute_reply.started": "2025-09-25T13:58:33.772779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers_advanced(df, target_col):\n",
    "    \"\"\"Advanced outlier removal using multiple methods\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    original_shape = df_clean.shape[0]\n",
    "    \n",
    "    # Method 1: Conservative percentile filtering for target\n",
    "    Q1 = df_clean[target_col].quantile(0.005)  # Very conservative\n",
    "    Q3 = df_clean[target_col].quantile(0.995)\n",
    "    df_clean = df_clean[(df_clean[target_col] >= Q1) & (df_clean[target_col] <= Q3)]\n",
    "    print(f\"After percentile filtering: {df_clean.shape[0]} rows ({original_shape - df_clean.shape[0]} removed)\")\n",
    "    \n",
    "    # Method 2: Z-score for extreme outliers in target\n",
    "    z_scores = np.abs(stats.zscore(df_clean[target_col]))\n",
    "    df_clean = df_clean[z_scores < 4]  # Remove extreme outliers\n",
    "    print(f\"After z-score filtering: {df_clean.shape[0]} rows\")\n",
    "    \n",
    "    # Method 3: Domain-specific filtering for music tracks\n",
    "    df_clean = df_clean[\n",
    "        (df_clean['TrackDurationMs'] >= 15000) &    # At least 15 seconds\n",
    "        (df_clean['TrackDurationMs'] <= 900000) &   # At most 15 minutes\n",
    "        (df_clean['InstrumentalScore'] <= 0.95) &   # Mostly non-instrumental\n",
    "        (df_clean['Energy'] >= 0) & (df_clean['Energy'] <= 1) &  # Valid energy range\n",
    "        (df_clean['MoodScore'] >= 0) & (df_clean['MoodScore'] <= 1)  # Valid mood range\n",
    "    ]\n",
    "    print(f\"After domain filtering: {df_clean.shape[0]} rows\")\n",
    "    print(f\"Total removed: {original_shape - df_clean.shape[0]} ({(original_shape - df_clean.shape[0])/original_shape*100:.1f}%)\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:37.786750Z",
     "iopub.status.busy": "2025-09-25T13:58:37.786429Z",
     "iopub.status.idle": "2025-09-25T13:58:37.803773Z",
     "shell.execute_reply": "2025-09-25T13:58:37.802801Z",
     "shell.execute_reply.started": "2025-09-25T13:58:37.786728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AdvancedEnsemble:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.weights = {}\n",
    "        \n",
    "    def get_lgb_model(self, trial=None):\n",
    "        if trial:\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 1000, 5000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 31, 511),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1,\n",
    "                'verbose': -1\n",
    "            }\n",
    "        else:\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'n_estimators': 4000,\n",
    "                'learning_rate': 0.04,\n",
    "                'num_leaves': 255,\n",
    "                'subsample': 0.85,\n",
    "                'colsample_bytree': 0.85,\n",
    "                'reg_alpha': 0.1,\n",
    "                'reg_lambda': 0.3,\n",
    "                'min_child_samples': 20,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1,\n",
    "                'verbose': -1\n",
    "            }\n",
    "        return lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    def get_xgb_model(self):\n",
    "        return xgb.XGBRegressor(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.04,\n",
    "            max_depth=6,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.3,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    # Uncomment if CatBoost is available\n",
    "    # def get_cat_model(self):\n",
    "    #     return cb.CatBoostRegressor(\n",
    "    #         iterations=4000,\n",
    "    #         learning_rate=0.04,\n",
    "    #         depth=6,\n",
    "    #         subsample=0.85,\n",
    "    #         colsample_bylevel=0.85,\n",
    "    #         reg_lambda=0.3,\n",
    "    #         random_state=42,\n",
    "    #         verbose=False\n",
    "    #     )\n",
    "    \n",
    "    def train_ensemble(self, X, y, X_test):\n",
    "        kf = KFold(n_splits=7, shuffle=True, random_state=42)  # More folds\n",
    "        \n",
    "        # Using 2 models instead of 3 if CatBoost not available\n",
    "        n_models = 2  # Change to 3 if you have CatBoost\n",
    "        oof_preds = np.zeros((len(X), n_models))\n",
    "        test_preds = np.zeros((len(X_test), n_models))\n",
    "        \n",
    "        models = [\n",
    "            ('lgb', self.get_lgb_model()),\n",
    "            ('xgb', self.get_xgb_model()),\n",
    "            # ('cat', self.get_cat_model())  # Uncomment if available\n",
    "        ]\n",
    "        \n",
    "        for model_idx, (model_name, model) in enumerate(models):\n",
    "            print(f\"\\nTraining {model_name.upper()}...\")\n",
    "            fold_oof = np.zeros(len(X))\n",
    "            fold_test = np.zeros(len(X_test))\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "                if model_name == 'lgb':\n",
    "                    model.fit(\n",
    "                        X_train_fold, y_train_fold,\n",
    "                        eval_set=[(X_val_fold, y_val_fold)],\n",
    "                        callbacks=[lgb.early_stopping(150), lgb.log_evaluation(0)]\n",
    "                    )\n",
    "                    val_pred = model.predict(X_val_fold, num_iteration=model.best_iteration_)\n",
    "                    test_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "                    \n",
    "                elif model_name == 'xgb':\n",
    "                    model.fit(\n",
    "                        X_train_fold, y_train_fold,\n",
    "                        eval_set=[(X_val_fold, y_val_fold)],\n",
    "                        early_stopping_rounds=150,\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    val_pred = model.predict(X_val_fold)\n",
    "                    test_pred = model.predict(X_test)\n",
    "                \n",
    "                # elif model_name == 'cat':  # Uncomment if available\n",
    "                #     model.fit(\n",
    "                #         X_train_fold, y_train_fold,\n",
    "                #         eval_set=(X_val_fold, y_val_fold),\n",
    "                #         early_stopping_rounds=150,\n",
    "                #         verbose=False\n",
    "                #     )\n",
    "                #     val_pred = model.predict(X_val_fold)\n",
    "                #     test_pred = model.predict(X_test)\n",
    "                \n",
    "                fold_oof[val_idx] = val_pred\n",
    "                fold_test += test_pred / kf.n_splits\n",
    "                \n",
    "                fold_rmse = mean_squared_error(y_val_fold, val_pred, squared=False)\n",
    "                print(f\"{model_name.upper()} Fold {fold+1} RMSE: {fold_rmse:.5f}\")\n",
    "            \n",
    "            oof_preds[:, model_idx] = fold_oof\n",
    "            test_preds[:, model_idx] = fold_test\n",
    "            \n",
    "            model_rmse = mean_squared_error(y, fold_oof, squared=False)\n",
    "            print(f\"{model_name.upper()} CV RMSE: {model_rmse:.5f}\")\n",
    "        \n",
    "        # Simple ensemble (equal weights for now)\n",
    "        final_oof = np.mean(oof_preds, axis=1)\n",
    "        final_test = np.mean(test_preds, axis=1)\n",
    "        \n",
    "        ensemble_rmse = mean_squared_error(y, final_oof, squared=False)\n",
    "        print(f\"\\nFinal Ensemble CV RMSE: {ensemble_rmse:.5f}\")\n",
    "        \n",
    "        return final_test, ensemble_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T13:58:41.806769Z",
     "iopub.status.busy": "2025-09-25T13:58:41.806451Z",
     "iopub.status.idle": "2025-09-25T14:01:13.273908Z",
     "shell.execute_reply": "2025-09-25T14:01:13.272912Z",
     "shell.execute_reply.started": "2025-09-25T13:58:41.806746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced features...\n",
      "Original train shape: (524164, 11)\n",
      "After feature engineering: (524164, 44)\n",
      "\n",
      "Removing outliers...\n",
      "After percentile filtering: 518968 rows (5196 removed)\n",
      "After z-score filtering: 518968 rows\n",
      "After domain filtering: 518968 rows\n",
      "Total removed: 5196 (1.0%)\n",
      "\n",
      "Removing highly correlated features...\n",
      "Dropped 13 highly correlated features: ['Duration_Minutes', 'Energy_Bin', 'Mood_Bin', 'Vocal_Bin', 'Energy_Squared', 'RhythmScore_Squared', 'MoodScore_Squared', 'VocalContent_Squared', 'TrackDurationMs_Log', 'AudioLoudness_Log', 'Audio_Features_Mean', 'Audio_Features_Std', 'Audio_Features_Range']\n",
      "Using 29 features for training\n",
      "\n",
      "Final shapes:\n",
      "X: (518968, 29)\n",
      "y: (518968,)\n",
      "X_test: (174722, 29)\n",
      "\n",
      "Training ensemble models...\n",
      "\n",
      "Training LGB...\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 25.589\n",
      "LGB Fold 1 RMSE: 25.58904\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's rmse: 25.5963\n",
      "LGB Fold 2 RMSE: 25.59629\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's rmse: 25.6568\n",
      "LGB Fold 3 RMSE: 25.65680\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 25.6427\n",
      "LGB Fold 4 RMSE: 25.64273\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's rmse: 25.523\n",
      "LGB Fold 5 RMSE: 25.52305\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's rmse: 25.5895\n",
      "LGB Fold 6 RMSE: 25.58950\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 25.6259\n",
      "LGB Fold 7 RMSE: 25.62588\n",
      "LGB CV RMSE: 25.60336\n",
      "\n",
      "Training XGB...\n",
      "XGB Fold 1 RMSE: 25.58726\n",
      "XGB Fold 2 RMSE: 25.59801\n",
      "XGB Fold 3 RMSE: 25.65232\n",
      "XGB Fold 4 RMSE: 25.64124\n",
      "XGB Fold 5 RMSE: 25.52206\n",
      "XGB Fold 6 RMSE: 25.58777\n",
      "XGB Fold 7 RMSE: 25.62372\n",
      "XGB CV RMSE: 25.60180\n",
      "\n",
      "Final Ensemble CV RMSE: 25.60131\n",
      "\n",
      "==================================================\n",
      "FINAL CROSS-VALIDATION RMSE: 25.60131\n",
      "==================================================\n",
      "Performance Rank: ðŸ† TOP TIER (Top 1%)\n",
      "Status: Excellent! You're in the top tier!\n",
      "\n",
      "Submission saved as 'submission_improved.csv'\n",
      "Submission shape: (174722, 2)\n",
      "Sample predictions:\n",
      "       id  BeatsPerMinute\n",
      "0  524164      119.109063\n",
      "1  524165      118.815959\n",
      "2  524166      119.148987\n",
      "3  524167      119.259262\n",
      "4  524168      119.324479\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Feature engineering\n",
    "    print(\"Creating advanced features...\")\n",
    "    train_fe = create_advanced_features(train)\n",
    "    test_fe = create_advanced_features(test)\n",
    "    \n",
    "    print(f\"Original train shape: {train.shape}\")\n",
    "    print(f\"After feature engineering: {train_fe.shape}\")\n",
    "    \n",
    "    # Advanced outlier removal\n",
    "    print(\"\\nRemoving outliers...\")\n",
    "    train_clean = remove_outliers_advanced(train_fe, 'BeatsPerMinute')\n",
    "    \n",
    "    # Prepare features\n",
    "    TARGET = \"BeatsPerMinute\"\n",
    "    ID_COL = \"id\"\n",
    "    \n",
    "    # Select features (exclude ID and target)\n",
    "    features = [c for c in train_clean.columns if c not in [ID_COL, TARGET]]\n",
    "    \n",
    "    # Remove highly correlated features to avoid overfitting\n",
    "    print(\"\\nRemoving highly correlated features...\")\n",
    "    corr_matrix = train_clean[features].corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    features = [f for f in features if f not in to_drop]\n",
    "    \n",
    "    print(f\"Dropped {len(to_drop)} highly correlated features: {to_drop}\")\n",
    "    print(f\"Using {len(features)} features for training\")\n",
    "    \n",
    "    # Handle categorical features created by pd.cut\n",
    "    for col in features:\n",
    "        if train_clean[col].dtype.name == 'category':\n",
    "            train_clean[col] = train_clean[col].astype(int)\n",
    "            test_fe[col] = test_fe[col].astype(int)\n",
    "    \n",
    "    X = train_clean[features]\n",
    "    y = train_clean[TARGET]\n",
    "    X_test = test_fe[features]\n",
    "    \n",
    "    print(f\"\\nFinal shapes:\")\n",
    "    print(f\"X: {X.shape}\")\n",
    "    print(f\"y: {y.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    \n",
    "    # Train ensemble\n",
    "    print(\"\\nTraining ensemble models...\")\n",
    "    ensemble = AdvancedEnsemble()\n",
    "    test_preds, cv_rmse = ensemble.train_ensemble(X, y, X_test)\n",
    "    \n",
    "    # Performance assessment\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"FINAL CROSS-VALIDATION RMSE: {cv_rmse:.5f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Competition benchmark comparison\n",
    "    if cv_rmse <= 26.30:\n",
    "        rank = \"ðŸ† TOP TIER (Top 1%)\"\n",
    "        status = \"Excellent! You're in the top tier!\"\n",
    "    elif cv_rmse <= 26.45:\n",
    "        rank = \"ðŸ¥ˆ HIGH TIER (Top 5%)\"\n",
    "        status = \"Great performance!\"\n",
    "    elif cv_rmse <= 26.80:\n",
    "        rank = \"ðŸ¥‰ MID-HIGH TIER (Top 15%)\"\n",
    "        status = \"Very good results!\"\n",
    "    elif cv_rmse <= 27.20:\n",
    "        rank = \"ðŸ“Š MID TIER (Top 35%)\"\n",
    "        status = \"Solid baseline with room for improvement\"\n",
    "    else:\n",
    "        rank = \"ðŸ“ˆ BASELINE TIER\"\n",
    "        status = \"Good starting point, significant improvement possible\"\n",
    "    \n",
    "    print(f\"Performance Rank: {rank}\")\n",
    "    print(f\"Status: {status}\")\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({ID_COL: test[ID_COL], TARGET: test_preds})\n",
    "    submission.to_csv(\"submission_improved.csv\", index=False)\n",
    "    print(f\"\\nSubmission saved as 'submission_improved.csv'\")\n",
    "    print(f\"Submission shape: {submission.shape}\")\n",
    "    print(f\"Sample predictions:\")\n",
    "    print(submission.head())\n",
    "    \n",
    "    return submission, cv_rmse\n",
    "\n",
    "# Run the improved solution\n",
    "if __name__ == \"__main__\":\n",
    "    submission, final_score = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13345277,
     "sourceId": 91720,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
